rownames(m) = m$Group.1
m = m[,-1]
pheatmap(t(m),scale = "row",clustering_method = "ward")
pheatmap(cor(t(assay(sce,"Raw_intensity"))),clustering_method = "ward")
pheatmap(cor(t(assay(sce,"Count_normalised_intensity"))),clustering_method = "ward")
m = aggregate(t(assay(sce,"Count_normalised_intensity")),FUN = mean,by=list(as.character(colLabels(sce))))
rownames(m) = m$Group.1
m = m[,-1]
pheatmap(t(m),scale = "row",clustering_method = "ward")
m = aggregate(t(assay(sce,"Raw_intensity")),FUN = mean,by=list(as.character(colLabels(sce))))
rownames(m) = m$Group.1
m = m[,-1]
pheatmap(t(m),scale = "row",clustering_method = "ward")
pheatmap(t(m),clustering_method = "ward")
sce = UMAP_embedding(sce,assay_type = "Raw_intensity",metric = "cosine")
plot_embedding(sce)
Count_normalization
sce = Count_normalization(sce,residual_normalisation = "VST")
sce = UMAP_embedding(sce,assay_type = "Raw_intensity",metric = "cosine")
sce = KNN_clustering(sce,K = 15,clustering_method = "Louvain",assay_type = "Count_normalised_intensity",metric = "angular")
plot_embedding(sce)
sce = UMAP_embedding(sce,assay_type = "Count_normalised_intensity",metric = "cosine")
plot_embedding(sce)
plot_embedding
reducedDimNames(sce)
reducedDim(sce)
x = reducedDim(sce)
.color_convertion=function(x,max_scale=NULL) {
f <- colorRamp(c("grey","yellow","orange","red"))
x=as.numeric(x)
if (is.null(max_scale)) {
max_scale=quantile(x,0.99,na.rm = TRUE)
}
x_prime=ifelse(x>max_scale,max_scale,x)
x_prime=x_prime/max_scale
x_color=f(x_prime)/255
x_color[!complete.cases(x_color),]=c(0,0,0)
x_color=rgb(x_color)
return(x_color)
}
plot(x,.color_convertion(assay(sce,"Count_normalised_intensity")[,"LEF1."]))
plot(x,pch=21,bg=.color_convertion(assay(sce,"Count_normalised_intensity")[,"LEF1."]))
plot(x)
sce,"Count_normalised_intensity")
assay(sce,"Count_normalised_intensity")[,"LEF1."])
assay(sce,"Count_normalised_intensity")[,"LEF1."]
assay(sce,"Count_normalised_intensity")
assay(sce,"Count_normalised_intensity")["LEF1.",]
plot(x,pch=21,bg=.color_convertion(assay(sce,"Count_normalised_intensity")["LEF1.",]))
plot(x,pch=21,bg=.color_convertion(assay(sce,"Count_normalised_intensity")["CD303",]))
plot(x,pch=21,bg=.color_convertion(assay(sce,"Count_normalised_intensity")["MX1",]))
sce = UMAP_embedding(sce,assay_type = "Count_normalised_intensity",metric = "L2")
sce = UMAP_embedding(sce,assay_type = "Count_normalised_intensity",metric = "euclidean")
x = reducedDim(sce)
plot(x,pch=21,bg=.color_convertion(assay(sce,"Count_normalised_intensity")["MX1",]))
plot(x,pch=21,bg=.color_convertion(assay(sce,"Count_normalised_intensity")["CD3",]))
hist(assay(sce,"Arcsinh_transformed_intensity")["MX1",])
hist(assay(sce,"Arcsinh_transformed_intensity")["MX1",],100)
hist(assay(sce,"Count_normalised_intensity")["MX1",],100)
hist(assay(sce,"Raw_intensity")["MX1",],100)
hist(assay(sce,"Count_normalised_intensity")["MX1",],100)
hist(assay(sce,"Count_normalised_intensity")["CD303",],100)
hist(assay(sce,"Count_normalised_intensity")["CD45$A",],100)
hist(assay(sce,"Count_normalised_intensity")["CD45RA",],100)
hist(assay(sce,"Count_normalised_intensity")["CD45R0",],100)
hist(assay(sce,"Count_normalised_intensity")["CD45RO",],100)
sce = Count_normalization(sce)
hist(assay(sce,"Count_normalised_intensity")["CD45RO",],100)
hist(assay(sce,"Count_normalised_intensity")["CD45RA",],100)
hist(assay(sce,"Raw_intensity")["CD45RA",],100)
hist(assay(sce,"Arcsinh_transformed_intensity")["CD45RA",],100)
hist(assay(sce,"Raw_intensity")["LEF.1",],100)
hist(assay(sce,"Raw_intensity")["LEF1.",],100)
hist(assay(sce,"Count_normalised_intensity")["LEF1.",],100)
hist(assay(sce,"Raw_intensity")["LEF1.",],100)
rownames(sce)
hist(assay(sce,"Raw_intensity")["FOXP3",],100)
hist(assay(sce,"Count_normalised_intensity")["FOXP3",],100)
hist(assay(sce,"Arcsinh_transformed_intensity")["FOXP3",],100)
rownames(sce)
hist(assay(sce,"Arcsinh_transformed_intensity")["human.IgM",],100)
hist(assay(sce,"Count_normalised_intensity")["human.IgM",],100)
hist(assay(sce,"Raw_intensity")["human.IgM",],100)
rownames(sce)
hist(assay(sce,"Raw_intensity")["CD31",],100)
hist(assay(sce,"Count_normalised_intensity")["CD31",],100)
hist(assay(sce,"Arcsinh_transformed_intensity")["CD31",],100)
Arcsinh_transformed_intensity
hist(assay(sce,"Arcsinh_transformed_intensity")[1,],100)
hist(assay(sce,"Arcsinh_transformed_intensity")[2,],100)
hist(assay(sce,"Count_normalised_intensity")[2,],100)
hist(assay(sce,"Count_normalised_intensity")[3,],100)
hist(assay(sce,"Count_normalised_intensity")[4,],100)
hist(assay(sce,"Count_normalised_intensity")[5,],100)
hist(assay(sce,"Count_normalised_intensity")[6,],100)
hist(assay(sce,"Count_normalised_intensity")[7,],100)
hist(assay(sce,"Raw_intensity")[7,],100)
hist(log(assay(sce,"Raw_intensity")[7,]),100)
hist(assay(sce,"Raw_intensity")[8,],100)
hist(assay(sce,"Raw_intensity")[9,],100)
hist(assay(sce,"Count_normalised_intensity")[9,],100)
metadata(sce)
if (metadata(sce)$Is_nuc_cyt) {
List_localisation = rowData(sce)[,"Localisation"]
names(List_localisation) = rownames(sce)
for (k in rownames(sce)) {
if (List_localisation[k]=="Cytoplasm") {
Object_size = sce$Cyto_size
}
if (List_localisation[k]=="Nuclear") {
Object_size = sce$Nuc_size
}
if (List_localisation[k]=="Cell") {
Object_size = sce$Cell_size
}
Transformed_data = t(assays(sce)[["Raw_intensity"]])
Transformed_data = Transformed_data * 2^metadata(sce)$Bit_mode
Transformed_data = apply(Transformed_data,MARGIN = 2,FUN = function(x) {x*Object_size})
Transformed_data = round(Transformed_data)
}
}
registerDoParallel(metadata(sce)$N_core)
library()
library(MASS)
glm.nb()
k="LEF1."
List_localisation
if (List_localisation[k]=="Cytoplasm") {
Object_size = sce$Cyto_size
}
if (List_localisation[k]=="Nuclear") {
Object_size = sce$Nuc_size
}
if (List_localisation[k]=="Cell") {
Object_size = sce$Cell_size
}
Object_size
hist(Object_size)
hist(Object_size,100)
plot(Object_size,Transformed_data[,k])
plot(Object_size,Transformed_data[,k],log="x")
NB_model = glm.nb(Transformed_data[,k]~log(Object_size),family = "poisson")
NB_model = glm.nb(Transformed_data[,k]~log(Object_size))
NB_model
NB_model$residuals
hist(NB_model)
hist(NB_model$residuals)
hist(NB_model$residuals,100)
Poisson_model$
Poisson_model = glm(Transformed_data[,k]~log(Object_size),family = "poisson")
NB_model$R
plot(Poisson_model$residuals,NB_model$residuals)
Count_normalization = function(sce,perform_batch_correction=FALSE,
batch_vector=NULL,residual_normalisation = "Anscombe") {
#Transforming the data back to count data
if (!"Cell_size"%in%colnames(colData(sce))) {
stop("The normalization procedure can not be performed as cell size is not available in the SCE object. Please select an other method or add a Cell_size column !")
}
#If 'simple data' -> direct resizing
if (!metadata(sce)$Is_nuc_cyt) {
Cell_size = sce$Cell_size
Transformed_data = t(assays(sce)[["Raw_intensity"]])
Transformed_data = Transformed_data * 2^metadata(sce)$Bit_mode
Transformed_data = apply(Transformed_data,MARGIN = 2,FUN = function(x) {x*Cell_size})
Transformed_data = round(Transformed_data)
}
#If localisation/specific data -> selecting the size of the adapted compartment
if (metadata(sce)$Is_nuc_cyt) {
List_localisation = rowData(sce)[,"Localisation"]
names(List_localisation) = rownames(sce)
for (k in rownames(sce)) {
if (List_localisation[k]=="Cytoplasm") {
Object_size = sce$Cyto_size
}
if (List_localisation[k]=="Nuclear") {
Object_size = sce$Nuc_size
}
if (List_localisation[k]=="Cell") {
Object_size = sce$Cell_size
}
Transformed_data = t(assays(sce)[["Raw_intensity"]])
Transformed_data = Transformed_data * 2^metadata(sce)$Bit_mode
Transformed_data = apply(Transformed_data,MARGIN = 2,FUN = function(x) {x*Object_size})
Transformed_data = round(Transformed_data)
}
}
#Creating parallel backend
cat(paste("Creating parallel backend using"),as.character(metadata(sce)$N_core),"cores \n")
registerDoParallel(metadata(sce)$N_core)
#Performing the poisson regression in the 'simple case'
if (!metadata(sce)$Is_nuc_cyt) {
cat("Fitting Poisson regressions ...")
List_regression_model =foreach(i=colnames(Transformed_data)) %dopar% {
Poisson_model = glm(Transformed_data[,i]~log(Cell_size),family = "poisson")
}
}
cat(" done ! \n")
#Performing the poisson regression in the complex case where signal is measured in each compartment
if (metadata(sce)$Is_nuc_cyt) {
cat("Fitting Poisson regressions ...")
List_regression_model =foreach(k=colnames(Transformed_data)) %dopar% {
if (List_localisation[k]=="Cytoplasm") {
Object_size = sce$Cyto_size
}
if (List_localisation[k]=="Nuclear") {
Object_size = sce$Nuc_size
}
if (List_localisation[k]=="Cell") {
Object_size = sce$Cell_size
}
#Poisson_model = glm(Transformed_data[,k]~log(Object_size),family = "poisson")
NB_model = glm.nb(Transformed_data[,k]~log(Object_size))
NB_model
}
}
cat(" done ! \n")
#Extracting and normalizing residuals
Residual_matrix =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
#Scaling to 0-1 values
Residual_matrix = apply(Residual_matrix,MARGIN = 2,FUN = function(x) {
x = x-min(x)
x = x/max(x)
})
Residual_matrix = as.data.frame(Residual_matrix)
colnames(Residual_matrix) = colnames(Transformed_data)
#Adding the matrix a new assay slot
assay(sce, "Count_normalised_intensity",withDimnames = FALSE) <- t(Residual_matrix)
return(sce)
}
sce = Count_normalization(sce)
hist(assay(sce,"Count_normalised_intensity")[9,],100)
hist(assay(sce,"Count_normalised_intensity")["LEF1.",],100)
List_regression_model_NB =foreach(k=colnames(Transformed_data)) %dopar% {
if (List_localisation[k]=="Cytoplasm") {
Object_size = sce$Cyto_size
}
if (List_localisation[k]=="Nuclear") {
Object_size = sce$Nuc_size
}
if (List_localisation[k]=="Cell") {
Object_size = sce$Cell_size
}
#Poisson_model = glm(Transformed_data[,k]~log(Object_size),family = "poisson")
NB_model = glm.nb(Transformed_data[,k]~log(Object_size))
NB_model
}
Residual_matrix_NB =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model_NB[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
Residual_matrix_NB =foreach(i=1:length(List_regression_model_NB),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model_NB[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
Fitted_values = List_regression_model_NB[[i]]$fitted.values
i
i=1
Fitted_values = List_regression_model_NB[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
residual_normalisation="Anscombe"
List_regression_model =foreach(k=colnames(Transformed_data)) %dopar% {
if (List_localisation[k]=="Cytoplasm") {
Object_size = sce$Cyto_size
}
if (List_localisation[k]=="Nuclear") {
Object_size = sce$Nuc_size
}
if (List_localisation[k]=="Cell") {
Object_size = sce$Cell_size
}
Poisson_model = glm(Transformed_data[,k]~log(Object_size),family = "poisson")
}
Residual_matrix_NB =foreach(i=1:length(List_regression_model_NB),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model_NB[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
Residual_matrix =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
plot(Residual_matrix)
Residual_matrix
plot(Residual_matrix[,1],Residual_matrix_NB[,1])
plot(Residual_matrix[,2],Residual_matrix_NB[,2])
plot(Residual_matrix[,3],Residual_matrix_NB[,3])
plot(Residual_matrix[,4],Residual_matrix_NB[,4])
residual_normalisation
Residual_matrix_Anscombe =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
residual_normalisation = "Pearson"
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
Residual_matrix_Pearson =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
Residual_matrix_Pearson
residual_normalisation="Working"
Residual_matrix_Working =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
residual_normalisation="VST"
Residual_matrix_VST =foreach(i=1:length(List_regression_model),.combine = cbind ) %dopar% {
Fitted_values = List_regression_model[[i]]$fitted.values
Real_values = Transformed_data[,i]
if (!residual_normalisation%in%c("Anscombe","Pearson","Working","VST")){
cat("No proper method for residual normalization provided. Using the Anscombe normalization method")
}
if (residual_normalisation=="Anscombe") {
Normalised_residuals = 1.5 * (Real_values^(2/3)-Fitted_values^(2/3)) / (Fitted_values^(1/6))
}
if (residual_normalisation=="Pearson") {
Normalised_residuals = (Real_values-Fitted_values)/sqrt(Fitted_values)
}
if (residual_normalisation=="Working") {
Normalised_residuals = (Real_values-Fitted_values)/Fitted_values
}
if (residual_normalisation=="VST") {
Normalised_residuals = (sqrt(Real_values)-sqrt(Fitted_values))/2
}
Normalised_residuals
}
plot(Residual_matrix_VST[,1],Residual_matrix_Anscombe[,1])
plot(Residual_matrix_VST[,2],Residual_matrix_Anscombe[,2])
pheatmap(cor(Residual_matrix_VST))
pheatmap(cor(Residual_matrix_VST),clustering_method = "ward.D")
pheatmap(cor(Residual_matrix_Anscombe),clustering_method = "ward.D")
colnames(Residual_matrix_VST) = colnames(Transformed_data)
colnames(Residual_matrix_Anscombe) = colnames(Transformed_data)
colnames(Residual_matrix_Pearson) = colnames(Transformed_data)
colnames(Residual_matrix_Working) = colnames(Transformed_data)
pheatmap(cor(Residual_matrix_VST),clustering_method = "ward.D")
pheatmap(cor(Residual_matrix_Anscombe),clustering_method = "ward.D")
pheatmap(cor(Residual_matrix_Pearson),clustering_method = "ward.D")
pheatmap(cor(Residual_matrix_Working),clustering_method = "ward.D")
sce = Count_normalization(sce,residual_normalisation = "Working")
sce = UMAP_embedding(sce,assay_type = "Count_normalised_intensity",metric = "euclidean")
sce = KNN_clustering(sce,K = 15,clustering_method = "Louvain",assay_type = "Count_normalised_intensity",metric = "angular")
plot_embedding(sce)
sce = Count_normalization(sce,residual_normalisation = "Anscombe")
UMAP_embedding
KNN_clustering
UMAP_embedding = function(sce,assay_type = "Count_normalised_intensity",metric="correlation",n_neighbors = 30,use) {
if (!assay_type%in%names(assays(sce))) {
stop("The slot required does not exist. Please select an existing slot !")
}
Channel_for_clustering = rowData(sce)$Used_for_clustering
#If no selection of the channels : using all channels
if (sum(Channel_for_clustering)==0) {
Channel_for_clustering = rep(TRUE,ncol(data_to_cluster))
}
data_to_project =assay(sce,assay_type)
data_to_project = t(data_to_project)
data_to_project = data_to_project[,Channel_for_clustering]
cat("Computing UMAP embedding...")
umap_embedding = umap(data_to_project,n_neighbors = n_neighbors,pca = NULL,metric = metric,verbose=F,fast_sgd = TRUE,n_threads = metadata(sce)$N_core)
cat(" done ! \n")
reducedDim(sce, "UMAP") <- umap_embedding
return(sce)
}
sce = UMAP_embedding(sce,assay_type = "Count_normalised_intensity",metric = "euclidean")
plot_embedding(sce)
sce = UMAP_embedding(sce,assay_type = "Count_normalised_intensity",metric = "cosine")
plot_embedding(sce)
sce = KNN_clustering(sce,K = 15,clustering_method = "Louvain",assay_type = "Count_normalised_intensity",metric = "angular")
plot_embedding(sce)
m = aggregate(t(assay(sce,"Raw_intensity")),FUN = mean,by=list(as.character(colLabels(sce))))
rownames(m) = m$Group.1
m = m[,-1]
pheatmap(t(m),scale",clustering_method = "ward")
pheatmap(t(m),scale="row",clustering_method = "ward")
m = aggregate(t(assay(sce,"Raw_intensity")),FUN = mean,by=list(as.character(colLabels(sce))))
rownames(m) = m$Group.1
m = m[,-1]
pheatmap(t(m),scale="row",clustering_method = "ward")
